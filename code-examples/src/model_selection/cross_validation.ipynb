{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "In diesem Notebook demonstieren wir die `hold-out cross validation` und die `k-fold cross validation` im Code.\n",
    "\n",
    "Beide Verfahren sind im `sklearn` für uns bereits implementiert:\n",
    "\n",
    "Die `hold-out cross validation` machen wir mittels der `train_test_split` Funktion.\n",
    "Die `k-fold cross validation` machen wir mittels der `cross_val_predict` Funktion.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Setup Code muss *nicht* verstanden werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = dict(\n",
    "    Train=sns.color_palette()[0],\n",
    "    Val=sns.color_palette()[3]\n",
    ")\n",
    "\n",
    "def plot_data(ax, data, x, y):\n",
    "    if 'kind' in data:\n",
    "        sns.scatterplot(x=data[x], y=data[y], ax=ax, hue=data['kind'], palette=palette)\n",
    "    else:\n",
    "        sns.scatterplot(x=data[x], y=data[y], ax=ax)\n",
    "    ax.set_xlim(0, df[x].max() + 1)\n",
    "    ax.set_ylim(0, df[y].max() + 500)\n",
    "\n",
    "def plot_model(ax, data, x, y, model):\n",
    "    plot_data(ax, data, x, y)\n",
    "    y_hat = model.predict(data[[x]])\n",
    "    sns.lineplot(x=data[x], y=y_hat, color='orange', linewidth=3, ax=ax)\n",
    "    return y_hat\n",
    "\n",
    "def plot_model_with_errors(ax, df: pd.DataFrame, x: str, y: str, model):\n",
    "    def plot_error(row):\n",
    "        # draw line from real point (media_income, media_house_value) to predicted point (media_income, media_house_value_hat)\n",
    "        ax.plot([row[x], row[x]], [row[y], row['y_hat']], c='red')\n",
    "    df = df.copy()\n",
    "    plot_model(ax, df, x, y, model)\n",
    "    df['y_hat'] = model.predict(df[[x]])\n",
    "    df.apply(plot_error, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Set Size: (159, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_data = pd.read_csv('data/fish.csv')[['Width', 'Weight']].rename(columns={\n",
    "    'Width': 'width (cm)',\n",
    "    'Weight': 'weight (g)'\n",
    "})\n",
    "\n",
    "print(f\"Data Set Size: {df_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold-out cross validation\n",
    "\n",
    "Wir machen folgendes im Code:\n",
    "\n",
    "1. Wir teilen die Daten `df_data` in Train-Set `df_train` und Validaiton-Set `df_val` auf.\n",
    "2. Wir trainieren zwei Modelle, eine Lineare Regression `lr_model` und ein Decision Tree `dt_model` jeweils auf dem Train-Set.\n",
    "3. Evaluieren wir die beiden trainierten Modelle auf dem Validation-Set, also auf den während dem Training ungesehenen Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: (111, 2)\n",
      "Val Set Size: (48, 2)\n",
      "MSE LinearRegression = 41406\n",
      "MSE RandomForestRegressor = 57950\n"
     ]
    }
   ],
   "source": [
    "# 1. Split data into train set and val set\n",
    "\n",
    "df_train, df_val = train_test_split(df_data, shuffle=True, test_size=0.3) # LR best\n",
    "\n",
    "print(f\"Train Set Size: {df_train.shape}\")\n",
    "print(f\"Val Set Size: {df_val.shape}\")\n",
    "\n",
    "\n",
    "# 2. Train a LinearRegression and DecisionTreeRegressor on the train set \n",
    "\n",
    "lr_model = LinearRegression()\n",
    "_ = lr_model.fit(X=df_train[['width (cm)']], y=df_train['weight (g)']) # Modell lernt (Lernphase)\n",
    "\n",
    "dt_model = DecisionTreeRegressor()\n",
    "_ = dt_model.fit(X=df_train[['width (cm)']], y=df_train['weight (g)']) # Modell lernt (Lernphase)\n",
    "\n",
    "# 3. Evaluate the LinearRegression and DecisionTreeRegressor on the val set \n",
    "\n",
    "lr_y_val_hat = lr_model.predict(df_val[['width (cm)']])\n",
    "dt_y_val_hat = dt_model.predict(df_val[['width (cm)']])\n",
    "\n",
    "y_val = df_val['weight (g)']\n",
    "print(\"MSE LinearRegression =\", round(mean_squared_error(y_val, lr_y_val_hat)))\n",
    "print(\"MSE DecisionTreeRegressor =\", round(mean_squared_error(y_val, dt_y_val_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen, dass eines der beiden Modelle besser ist auf dem Validation-Set.\n",
    "\n",
    "Führen wir die Zelle mehrfach aus, sehen wir, dass es sehr zufällig ist, welches Modell besser ist. Dies liegt am zufälligen Split der Daten in `train_test_split` und dem (zu) kleinen Validation Set von 48 Datenpunkten.\n",
    "Es ist natürlich schlecht, da man nicht abhängig vom Zufall (zufälligen Split) entscheiden möchte, welches Modell besser ist, für welches Modell man sich entscheidet.\n",
    "\n",
    "Was können wir tun?\n",
    "\n",
    "Generell kann man das Validation Set vergrössern. Je grösser das Validation Set desto weniger wahrscheinlich, dass ein Modell nur durch Zufall gut auf den ungesehenen Daten ist.\n",
    "\n",
    "Wir können das Validation Set indirekt vergrössern mit dem k-fold cross validation Verfahren. Mit dem k-fold cross validation Verfahren ist jeder Datenpunkt einmal im Validation-Set.\n",
    "\n",
    "Speziell bei wenig Daten (unter 1000) sollte man immer k-fold cross validation verwenden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Fold cross validation\n",
    "\n",
    "Das `k-fold cross validation` Verfahren ist hier im Code gar nicht mehr sichtbar, da das Verfahren in `cross_val_predict` ausgeführt wird. In den Slides wir das Verfahren erklärt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bemerkung: Wir verwenden hier alle Daten als Validation Set: 48\n",
      "MSE LinearRegression = 34521\n",
      "MSE RandomForestRegressor = 57660\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "df = df_data\n",
    "# df = df_data.sample(n=120)  # Extra: Simulate random subsets of data to show robustness of k-Fold cross validation\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "dt_model = DecisionTreeRegressor()\n",
    "\n",
    "lr_y_hat = cross_val_predict(lr_model, X=df[['width (cm)']], y=df['weight (g)'], cv=10)\n",
    "dt_y_hat = cross_val_predict(dt_model, X=df[['width (cm)']], y=df['weight (g)'], cv=10)\n",
    "\n",
    "y = df['weight (g)']\n",
    "print(\"MSE LinearRegression =\", round(mean_squared_error(y, lr_y_hat)))\n",
    "print(\"MSE RandomForestRegressor =\", round(mean_squared_error(y, dt_y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir die obere Zeile mehrfach ausführen, sehen wir immer die gleiche Evaluation. Dies ist weil es keinen Zufall mehr gibt, da es keinen zufälligen Validation Split mehr gibt.\n",
    "\n",
    "Um einen realistischen Zufall zu simulieren, kann man die Zeile einkommentieren. Sie wählt zufällig 120 Beispiele aus dem Datensatz aus. Dies soll den Datenbeschaffungsprozess simulieren, welcher zufällig ist. Wir \"fangen\" sozusagen immer 120 andere Fische."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
