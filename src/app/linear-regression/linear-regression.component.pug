ng-template('#slides'='')
    section
        title-page
            h1 Linear Regression
    tables-of-content-machine-learning-algorithm([active]="linearRegressionLabels.LINEAR_REGRESSION")
    tables-of-content-machine-learning-algorithm([active]="linearRegressionLabels.DATA_SPECIFICATION")
    section
        slide-with-header(header="Linear Regression - Data Specification")
            div #[span.highlight Data Specification]: In welcher Form erwartet der Machine Learning Algorithmus die Daten.
            ul
                li.fragment Was ist die #[span.highlight Ziel-Variable], z.B. #[span.code-font weight (g)]
                li.fragment Welche #[span.highlight Features] wählen wir, z.B. um einen Fisch zu repräsentieren (#[span.code-font width (cm), ...])
                li.fragment Kategorische Features (z.B. Fisch-Art) müssen für das Modell #[span.highlight encoded] werden.
                // li.fragment
                //     div #[span.highlight Anzahl Features] gibt die #[span.highlight Anzahl Parameter] vor.
                //     div Also #[span.highlight mehr Features machen das Modell komplexer].
                // li Features müssen für das Modell #[span.highlight nicht skaliert] werden
                // li Label muss je nach Problemfall #[span.highlight transformiert] werden (Tusky-Anscombe Plot)
    tables-of-content-machine-learning-algorithm([active]="linearRegressionLabels.MODEL")
    section
        slide-with-header(header="Linear Regression - Intuition")
            p Wir möchten das #[span.highlight Gewicht] (weight) anhand eines einzigen Features, der #[span.highlight Breite] (width) vorhersagen.
            .row
                .col-6
                    div.r-stack
                        img(src="/assets/images/data.png", data-fragment-index="0").fragment
                        img(src="/assets/images/data-with-linear-regression-model.png", data-fragment-index="2").fragment
                .col-6
                    .fragment(data-fragment-index="1") Dazu verwenden wir das folgende #[span.highlight Lineare Modell]
                        div([mathjax]="linearRegression1DExample")
            div.d-flex.justify-content-center.fragment
                model-visualization
                    div(input, class="input").transparent-border-1.code
                        | width: 5cm
                    div(model, class="model").model-box.code
                        div([mathjax]="linearRegression1DExample")
                    div(output, class="output").fix-height.code
                        | weight: 508g
    section
        slide-with-header(header="Linear Regression - Code")
            div.notebook-name Teil 1 in linear_regression.ipynb
            img(src="/assets/images/code.png")
    section
        slide-with-header(header="Linear Regression - Theory - Verallgemeinern")
            ul
                li Wir möchten das lineare Modell verallgemeinern
                    ol
                        li Unabhängig  vom Problem
                        li Mehrere Features
                        li Bezug zu echten Beobachtungen
    section
        slide-with-header(header="Linear Regression - Theory - Verallgemeinern")
            ul
                li Wir möchten das lineare Modell verallgemeinern
                    ol
                        li.highlight-step Unabhängig  vom Problem
                        li.unhighlight-step Mehrere Features
                        li.unhighlight-step Bezug zu echten Beobachtungen
            div.mt-5.d-flex.justify-start.flex-column
                div([mathjax]="linearRegressionGeneralize1DExample")
    section
        slide-with-header(header="Linear Regression - Theory - Verallgemeinern")
            ul
                li Wir möchten das lineare Modell verallgemeinern
                    ol
                        li.unhighlight-step Unabhängig  vom Problem
                        li.highlight-step  Mehrere Features
                        li.unhighlight-step Bezug zu echten Beobachtungen
            div.mt-5.d-flex.justify-start.flex-column
                div([mathjax]="linearRegression1DToNDExample")
            div.fragment.text-center.alert.alert-primary Output ist eine #[span.highlight Gewichtete Summe] der Features
    section
        slide-with-header(header="Linear Regression - Theory - Verallgemeinern")
            ul
                li Wir möchten das lineare Modell verallgemeinern
                    ol
                        li.unhighlight-step Unabhängig  vom Problem
                        li.unhighlight-step Mehrere Features
                        li.highlight-step Bezug zu echten Beobachtungen
            div.mt-5.d-flex.justify-start.flex-column
                div([mathjax]="linearRegressionFull")
    section
        slide-with-header(header="\"Ganz simple Mathematik\"")
            div([mathjax]="linearRegressionMathematicalNotation")
            p.fragment.text-center.alert.alert-primary #[span.highlight Nur Notation]: Alle bedeutet das #[span.highlight Gleiche]!

    section
        slide-with-header(header="Linear Regression - Mehrere Features", [extra]="true")
            side-by-side-3
                div(first).d-flex.flex-column
                    h3 1 Feature
                    div([mathjax]="linearRegression1D", style={fontSize: "14pt"})
                    img(src="/assets/images/data-with-linear-regression-model-1d.png").fragment
                div(second).d-flex.flex-column
                    h3 2 Feature
                    div([mathjax]="linearRegression2D", style={fontSize: "14pt"})
                    img(src="/assets/images/data-with-linear-regression-model-2d.png").fragment
                div(third).d-flex.flex-column
                    h3 3 Feature
                    div([mathjax]="linearRegression3D", style={fontSize: "14pt"})
                    div.fragment
                        div(style={marginTop: "100px"}).w-100
                            div.m-auto ???
            p.fragment.text-center.alert.alert-primary #[span.highlight Visualisierung] gut für #[span.highlight Intuition].#[br]#[span.highlight Mathematik] verallgemeinert auf #[span.highlight höhere Dimensionen].
    section
        slide-with-header(header="Linear Regression - Limits", [extra]="true")
            div.row
                div.col-5.offset-1
                    h6 Possible
                div.col-5
                    h6 Impossible (in Feature Space)
                div.col-1
            div.row.fragment
                div.col-1.m-auto
                    h6(style={transform: "rotate(-90deg)", whiteSpace: 'nowrap'}) 1 Feature
                div.col-5.p-2
                    img(src="/assets/images/data-with-linear-regression-model-1d.png").limit-possible
                div.col-5.p-2
                    img(src="/assets/images/polynomial-regression.png").limit-impossible
                div.col-1
            div.row.fragment
                div.col-1.m-auto
                    h6(style={transform: "rotate(-90deg)", whiteSpace: 'nowrap'}) 2 Features
                div.col-5.p-2
                    img(src="/assets/images/data-with-linear-regression-model-2d.png").limit-possible
                div.col-5.p-2
                    img(src="/assets/images/polynomial-regression-2d.png").limit-impossible
                div.col-1
    section
        slide-with-header(header="Linear Regression - Wissens Ansicht")
            div
                p.fragment Wissen kann von #[span.highlight Experten] oder aus #[span.highlight Daten] kommen
            div.d-flex.justify-center
                knowledge-view("#knowledgeView"="", human-label="Lineares Modell, MSE", [tradeoff]="0.9" ).fragment
            span.fragment(fragment-trigger, "(trigger)"="knowledgeView.start()", "(untrigger)"="knowledgeView.end()")
    question-slide([questions]="linearRegressionQuestions")
    tables-of-content-concepts([active]="conceptLabels.METRICS")
    section
        title-page
            h1 Fehler, Metrik, Kostenfunktion
    section
        slide-with-header(header="{{problemLabels.REGRESSION.label}} - Fehler eines Modells messen?")
            ul
                li.fragment
                    div #[span.highlight Residuals] messen Fehler pro Datenpunkt
                    div.d-flex.justify-center
                        img(style={width: "350px"}, src="/assets/images/linear-regression-model-residuals.png").img-fluid
                    div([mathjax]='metricResiduals')
                li.fragment Residuals zu einer Zahl zusammenfassen => #[span.highlight Metrik]
    section
        slide-with-header(header="{{problemLabels.REGRESSION.label}} - Metrik")
            ul
                li Wie gewichten wir die Fehler pro Datenpunkt?
                    ul.fragment
                        li Sind alle Fehler gleich zu bewerten?
                        li Sind gröbere Fehler mehr zu bestrafen?
                        li Sind Fehler Absolut oder Prozentual zu bestrafen?
                li.fragment Die Wahl der #[span.highlight Metrik] gibt vor wie Fehler zu gewichten sind.
            p.fragment.text-center.alert.alert-primary Welche Metrik ist #[span.highlight Problemabhängig]!
    section
        slide-with-header(header="{{problemLabels.REGRESSION.label}} - Metrik - Beispiele")
            ul
                li.fragment #[span.highlight MAE]: #[span.highlight M]ean #[span.highlight A]bsolute #[span.highlight E]rror
                    div.r-stack
                        div.fragment([mathjax]="metricMeanAbsoluteError")
                        div.fragment([mathjax]="metricMeanAbsoluteErrorE")
                        div.fragment([mathjax]="metricMeanAbsoluteErrorA")
                        div.fragment([mathjax]="metricMeanAbsoluteErrorM")
                        div.fragment([mathjax]="metricMeanAbsoluteError")
                li.fragment
                    div #[span.highlight MSE]: #[span.highlight M]ean #[span.highlight S]quared #[span.highlight E]rror
                    div.r-stack
                        div.fragment([mathjax]="metricMeanSquaredError")
                        div.fragment([mathjax]="metricMeanSquaredErrorE")
                        div.fragment([mathjax]="metricMeanSquaredErrorS")
                        div.fragment([mathjax]="metricMeanSquaredErrorM")
                        div.fragment([mathjax]="metricMeanSquaredError")
            p.fragment.text-center.alert.alert-primary MSE bestraft im Vergleich zu MAE Fehler grösser 1 stärker und Fehler kleiner 1 schwächer.
    tables-of-content-concepts([active]="conceptLabels.COST_FUNCTION")
    section
        slide-with-header([header]="'Kostenfunktion'")
            div(style={marginBottom: "-10px"}).fragment
                div([mathjax]="metricCostFunctionMSE")
            div.mt-5.fragment Beispiel (Lineare Regression mit 2 Parameter):
                div([mathjax]="metricCostFunctionMSE1D")
            p.fragment.text-center.alert.alert-warning Synonym: #[span.highlight Cost function] = Loss f. = Objective f.
    tables-of-content-machine-learning-algorithm([active]="linearRegressionLabels.COST_FUNCTION")
    section
        slide-with-header(header="Linear Regression - Theory", [extra]="true")
            div.d-flex.flex-row
                div([mathjax]="noiseNormalDistributed").fragment
    section
        slide-with-header(header="Linear Regression - Code")
            div.notebook-name Teil 2 in in linear_regression.ipynb
            img(src="/assets/images/code.png")
    tables-of-content-concepts([active]="conceptLabels.OPTIMIZATION_ALGORITHMS")
    section
        slide-with-header(header="Optimierung")
            ul
                li
                    | Optimierung ist der Mechanismus, wie wir die #[span.highlight lernbaren Parameter] eines Models
                    | für eine #[span.highlight Kostenfunktion] aus #[span.highlight Daten] lernen.
                li.fragment Unterschiedliche Optimierungs-Algorithmen existieren
                li.fragment Unterschiedliche Garantien
                    ul
                        li #[span.highlight Performanz]: Wie schnell
                        li #[span.highlight Generalisierung]: Qualität
    tables-of-content-machine-learning-algorithm([active]="linearRegressionLabels.OPTIMIERUNG")
    section
        slide-with-header(header="Linear Regression - Kostenfunktion - Visuell")
            div.mt-5.d-flex.justify-center
                img(src="/assets/images/gradient-descent/gradient_descent_cost_function.png").fragment
            p.fragment.text-center.alert.alert-primary Schüssel nennt man #[span.highlight Convex Cost function]
    section
        slide-with-header(header="Linear Regression - Optimierung - Analytisch", [repetition]="'Regression'")
            p(style={marginTop: "-20px"}).fragment Idee: Wir lösen folgende Gleichung:
            div.d-flex.justify-center(style={marginTop: "-10px"})
                div([mathjax]="linearRegressionAnalytic").fragment
            div.fragment.d-flex.justify-center
                img(src="/assets/images/gradient-descent/gradient_descent_solution.png").fragment
            p.fragment.text-center.alert.alert-warning Nur bei #[span.highlight Convex Cost function] möglich
    section
        slide-with-header(header="Linear Regression - Optimierung - Gradient Descent")
            p Alternative Methode zur Analytischen Methode zum setzen der Parameter (betas)
            div.r-stack
                img(src="/assets/images/gradient-descent/gradient_descent_solution.png").fragment
                img(src="/assets/images/gradient-descent/gradient_descent_step_0.png").fragment
                img(src="/assets/images/gradient-descent/gradient_descent_step_1.png").fragment
                img(src="/assets/images/gradient-descent/gradient_descent_step_2.png").fragment
                img(src="/assets/images/gradient-descent/gradient_descent_step_3.png").fragment
                img(src="/assets/images/gradient-descent/gradient_descent_step_4.png").fragment
                img(src="/assets/images/gradient-descent/gradient_descent_step_5.png").fragment
    section
        slide-with-header(header="Linear Regression - Optimierung - Gradient Descent")
            p Wie finden wir die #[span.highlight Richtung] herunter?
            p.fragment.highlight Richtung entspricht der Steigung der Kostenfunktion!
            p.fragment Wie finden wir die #[span.highlight Steigung] einer Funktion?
            p.fragment Analysis => Die #[span.highlight Ableitung] der Kostenfunktion gibt uns die Steigung/Richtung.
            div([mathjax]="metricCostFunctionDerivative").fragment
    section
        slide-with-header(header="Optimierung - Gradient Descent")
            div #[span.highlight Gradient Descent]-Algorithmus funktioniert wie folgt:
            ol
                li.fragment.mt-5
                    div.d-flex.align-end(style={alignItems: "stretch"})
                        div.align-self-end Initialisiere:&nbsp;
                        div.align-self-end([mathjax]="gradientDescentInit")
                        div.align-self-end mit zufälligen Werten.
                li.fragment.mt-5
                    div.d-flex.align-end(style={alignItems: "stretch"})
                        div.align-self-end Aktualisiere:&nbsp;
                        div.align-self-end([mathjax]="gradientDescentUpdate")
            p.fragment.text-center.alert.alert-primary Auch bei #[span.highlight Non Convex Cost function] möglich
            p.mt-5.fragment.text-center.alert.alert-warning In der Praxis wird die #[span.highlight Analytische Methode für Lineare Regression] eingesetzt (schneller)
            // div.fragment
            //     div.mt-5.d-flex.justify-center.align-end(style={alignItems: "stretch"})
            //         div.align-self-end Wiederhole Schritt 2. bis&nbsp;
            //         div([mathjax]="gradientDescentStop")
    tables-of-content-machine-learning-algorithm
        div.row
            div.col-12
                div.d-flex.justify-start.flex-column.scale-05
                    div([mathjax]="linearRegressionFinal")
        div.row
            div.col-6
                div.d-flex.justify-start.flex-column.scale-05
                    div([mathjax]="metricMeanSquaredError")
            div.col-6
                img(src="/assets/images/gradient-descent/gradient_descent_step_5.png").img-fluid