ng-template('#slides'='')
    tables-of-content-machine-learning-algorithm([active]="linearRegressionLabels.LINEAR_REGRESSION")
    tables-of-content-machine-learning-algorithm([active]="linearRegressionLabels.DATA_SPECIFICATION")
    section
        slide-with-header(header="Linear Regression - Data Specification")
            // div #[span.highlight Data Specification]: In welcher Form erwartet der Machine Learning Algorithmus die Daten.
            ul
                li.fragment Was ist die kontinuierliche #[span.highlight Ziel-Variable], z.B. #[span.code-font weight (g)]
                li.fragment Welche #[span.highlight Features] wählen wir, z.B. um einen Fisch zu repräsentieren (#[span.code-font width (cm), ...])
                li.fragment
                    data-specification-element-categorical-feature-encoded
                li.fragment
                    span Wenn #[a(href="#/{{conceptLabels.REGULARIZATION.href}}") Regularisiert]:&nbsp;
                    data-specification-element-numerical-feature-standardize
                // li.fragment
                //     div #[span.highlight Anzahl Features] gibt die #[span.highlight Anzahl Parameter] vor.
                //     div Also #[span.highlight mehr Features machen das Modell komplexer].
                // li Features müssen für das Modell #[span.highlight nicht skaliert] werden
                // li Label muss je nach Problemfall #[span.highlight transformiert] werden (Tusky-Anscombe Plot)
    tables-of-content-machine-learning-algorithm([active]="linearRegressionLabels.MODEL")
    section
        slide-with-header(header="Linear Regression - Intuition")
            p Wir möchten das #[span.highlight Gewicht] (weight) anhand eines einzigen Features, der #[span.highlight Breite] (width) vorhersagen.
            .row
                .col-6
                    div.r-stack
                        img(src="assets/images/data.png", data-fragment-index="0").fragment
                        img(src="assets/images/data-with-linear-regression-model.png", data-fragment-index="2").fragment
                .col-6
                    .fragment(data-fragment-index="1") Dazu verwenden wir das folgende #[span.highlight Lineare Modell]
                        div([mathjax]="linearRegression1DExample")
            div.mt-5.d-flex.justify-content-center.fragment
                model-visualization(input-header="Input Space", output-header="Output Space")
                    div(input, class="input").transparent-border-1.code
                        | width: 5cm
                    div(model, class="model").model-box.code
                        div([mathjax]="linearRegression1DExample")
                    div(output, class="output").fix-height.code
                        | weight: 508g
    section
        slide-with-header(header="Linear Regression - Code")
            div.notebook-name Teil 1 in linear_regression.ipynb
            img(src="assets/images/code.png")
    section
        slide-with-header(header="Linear Regression - Theory - Verallgemeinern")
            ul
                li Wir möchten das lineare Modell verallgemeinern
                    ol
                        li Unabhängig  vom Problem
                        li Mehrere Features
                        li Bezug zu echten Beobachtungen
    section
        slide-with-header(header="Linear Regression - Theory - Verallgemeinern")
            ul
                li Wir möchten das lineare Modell verallgemeinern
                    ol
                        li.highlight-step Unabhängig  vom Problem
                        li.unhighlight-step Mehrere Features
                        li.unhighlight-step Bezug zu echten Beobachtungen
            div.mt-5.d-flex.justify-start.flex-column
                div([mathjax]="linearRegressionGeneralize1DExample")
    section
        slide-with-header(header="Linear Regression - Theory - Verallgemeinern")
            ul
                li Wir möchten das lineare Modell verallgemeinern
                    ol
                        li.unhighlight-step Unabhängig  vom Problem
                        li.highlight-step  Mehrere Features
                        li.unhighlight-step Bezug zu echten Beobachtungen
            div.mt-5.d-flex.justify-start.flex-column
                div([mathjax]="linearRegression1DToNDExample")
            div.fragment.text-center.alert.alert-primary Output ist eine #[span.highlight Gewichtete Summe] der Features
    section
        slide-with-header(header="Linear Regression - Theory - Verallgemeinern")
            ul
                li Wir möchten das lineare Modell verallgemeinern
                    ol
                        li.unhighlight-step Unabhängig  vom Problem
                        li.unhighlight-step Mehrere Features
                        li.highlight-step Bezug zu echten Beobachtungen
            div.mt-5.d-flex.justify-start.flex-column
                div([mathjax]="linearRegressionFull")
    section
        slide-with-header(header="\"Ganz simple Mathematik\"")
            div([mathjax]="linearRegressionMathematicalNotation")
            p.fragment.text-center.alert.alert-primary #[span.highlight Nur Notation]: Alle bedeutet das #[span.highlight Gleiche]!

    section
        slide-with-header(header="Linear Regression - Mehrere Features", [extra]="true")
            side-by-side-3
                div(first).d-flex.flex-column
                    h3 1 Feature
                    div([mathjax]="linearRegression1D", style={fontSize: "14pt"})
                    img(src="assets/images/data-with-linear-regression-model-1d.png").fragment
                div(second).d-flex.flex-column
                    h3 2 Feature
                    div([mathjax]="linearRegression2D", style={fontSize: "14pt"})
                    div.r-stack
                        img(src="assets/images/data-2d.png").fragment
                        img(src="assets/images/data-with-linear-regression-model-2d.png").fragment
                div(third).d-flex.flex-column
                    h3 3 Feature
                    div([mathjax]="linearRegression3D", style={fontSize: "14pt"})
                    div.fragment
                        div(style={marginTop: "100px"}).w-100
                            div.m-auto ???
            p.fragment.text-center.alert.alert-primary #[span.highlight Visualisierung] gut für #[span.highlight Intuition].#[br]#[span.highlight Mathematik] verallgemeinert auf #[span.highlight höhere Dimensionen].
    question-slide([questions]="linearRegressionQuestions")
    tables-of-content-concepts([active]="conceptLabels.REGRESSION_METRICS")
    section
        slide-with-header(header="{{problemLabels.REGRESSION.label}} - Fehler eines Modells messen?")
            ul
                li.fragment
                    div #[span.highlight Residuals] messen Fehler pro Datenpunkt
                    div.d-flex.justify-center
                        img(style={width: "350px"}, src="assets/images/linear-regression-model-residuals.png").img-fluid
                    div([mathjax]='metricResiduals')
                li.fragment Residuals zu einer Zahl zusammenfassen => #[span.highlight Metrik]
    section
        slide-with-header(header="{{problemLabels.REGRESSION.label}} - Metrik")
            ul
                li Wie gewichten wir die Fehler pro Datenpunkt?
                    ul.fragment
                        li Sind alle Fehler gleich zu bewerten?
                        li Sind gröbere Fehler mehr zu bestrafen?
                        li Sind Fehler Absolut oder Prozentual zu bestrafen?
                li.fragment Die Wahl der #[span.highlight Metrik] gibt vor wie Fehler zu gewichten sind.
            p.mt-5.fragment.text-center.alert.alert-primary Welche Metrik geeignet ist, ist #[span.highlight Problemabhängig]!
    section
        slide-with-header(header="{{problemLabels.REGRESSION.label}} - Metrik - Beispiele")
            ul
                li.fragment #[span.highlight MAE]: #[span.highlight M]ean #[span.highlight A]bsolute #[span.highlight E]rror
                    div.r-stack
                        div.fragment([mathjax]="metricMeanAbsoluteError")
                        div.fragment([mathjax]="metricMeanAbsoluteErrorE")
                        div.fragment([mathjax]="metricMeanAbsoluteErrorA")
                        div.fragment([mathjax]="metricMeanAbsoluteErrorM")
                        div.fragment([mathjax]="metricMeanAbsoluteError")
                li.fragment
                    div #[span.highlight MSE]: #[span.highlight M]ean #[span.highlight S]quared #[span.highlight E]rror
                    div.r-stack
                        div.fragment([mathjax]="metricMeanSquaredError")
                        div.fragment([mathjax]="metricMeanSquaredErrorE")
                        div.fragment([mathjax]="metricMeanSquaredErrorS")
                        div.fragment([mathjax]="metricMeanSquaredErrorM")
                        div.fragment([mathjax]="metricMeanSquaredError")
            p.fragment.text-center.alert.alert-primary MSE bestraft im Vergleich zu MAE Fehler grösser 1 stärker und Fehler kleiner 1 schwächer.
    tables-of-content-concepts([active]="conceptLabels.COST_FUNCTION")
    section
        slide-with-header([header]="'Kostenfunktion'")
            div(style={marginBottom: "-10px"}).fragment
                div([mathjax]="metricCostFunctionMSE")
            div.mt-5.fragment Beispiel (Lineare Regression mit 2 Parameter):
                div([mathjax]="metricCostFunctionMSE1D")
            p.fragment.text-center.alert.alert-warning Synonym: #[span.highlight Kostenfunktion] = Loss f. = Objective f.
    tables-of-content-machine-learning-algorithm([active]="linearRegressionLabels.COST_FUNCTION")
    section
        slide-with-header(header="Linear Regression - Kostenfunktion")
            div([mathjax]="metricCostFunctionMSECompact")
            div.fragment.mt-5.text-center.alert.alert-primary
                div Im #[span.code-font sklearn] wird #[span.code-font LinearRegression] nach der MSE-Kostenfunktion optimiert.
                div Es wären andere Kostenfunktionen möglich.
    // section
    //     slide-with-header(header="Linear Regression - Kostenfunktion - Motivation", [extra]="true")
    //         div.small-font
    //             .row
    //                 .col-6
    //                     h5 Annahmen
    //                     ul
    //                         li #[span.highlight Lineares Modell]: Linearer Zusammenhang von Ziel und Features plus ein unabhängiger Fehler
    //                         li Der unabhängige Fehler ist normalverteilt: #[span([mathjax]="noiseNormalDistributed")]
    //                 .col-6
    //                     h5 Konsequenzen
    //                     div Diese Annahmen führt #[span.highlight mathematisch zur MSE Metrik].
    //         div.mt-3
    //             img(src="assets/images/regression/linear-regression-cost-function-motivation.png", height="290px")
    //         div.mt-3.fragment.text-center.alert.alert-primary "Der Fehler ist normalverteilt" ist motiviert durch das #[a.highlight(href="https://en.wikipedia.org/wiki/Central_limit_theorem") Central Limit Theorem]
    section
        slide-with-header(header="Linear Regression - Code")
            div.notebook-name Teil 2 in in linear_regression.ipynb
            img(src="assets/images/code.png")
    tables-of-content-concepts([active]="conceptLabels.OPTIMIZATION_ALGORITHMS")
    section
        slide-with-header(header="Optimierung")
            ul
                li
                    | Optimierung ist der Mechanismus, wie wir die #[span.highlight lernbaren Parameter] eines Models
                    | für eine #[span.highlight Kostenfunktion] aus #[span.highlight Daten] lernen.
                li.fragment Unterschiedliche Optimierungs-Algorithmen existieren
                li.fragment Unterschiedliche Garantien
                    ul
                        li #[span.highlight Performanz]: Wie schnell
                        li (#[span.highlight Generalisierung]: Qualität)
    tables-of-content-machine-learning-algorithm([active]="linearRegressionLabels.OPTIMIERUNG")
    section
        slide-with-header(header="Linear Regression - Kostenfunktion - Visuell")
            div Folgende Funktion #[span([mathjax]="metricCostFunctionMSE1DCompact")] visualisiert für einen bestimmten Datensatz:
            div.d-flex.justify-center
                img(src="assets/images/gradient-descent/gradient_descent_cost_function.png").fragment
            p.fragment.text-center.alert.alert-primary Schüssel nennt man #[span.highlight Convex Kostenfunktion]
    section
        slide-with-header(header="Linear Regression - Optimierung - Analytisch", [repetition]="'Regression'")
            p(style={marginTop: "-20px"}).fragment Idee: Wir lösen folgende Gleichung:
            div.d-flex.justify-center(style={marginTop: "-10px"})
                div([mathjax]="linearRegressionAnalytic").fragment
            div.fragment.d-flex.justify-center
                img(src="assets/images/gradient-descent/gradient_descent_solution.png").fragment
            p.fragment.text-center.alert.alert-warning Nur bei #[span.highlight bestimmten Funktionen] möglich
    tables-of-content-concepts([active]="conceptLabels.GRADIENT_DESCENT")
    section
        slide-with-header(header="Linear Regression - Optimierung - Gradient Descent")
            p Alternative Methode zur Analytischen Methode zum setzen der #[span.highlight lernbaren Parameter]
                | &nbsp;
                | (
                span.equation.equation-colored(mathjax="<math><mi class='weight'>β</mi></math>")
                | )
            div.r-stack
                img(src="assets/images/gradient-descent/gradient_descent_solution.png").fragment
                img(src="assets/images/gradient-descent/gradient_descent_step_0.png").fragment
                img(src="assets/images/gradient-descent/gradient_descent_step_1.png").fragment
                img(src="assets/images/gradient-descent/gradient_descent_step_2.png").fragment
                img(src="assets/images/gradient-descent/gradient_descent_step_3.png").fragment
                img(src="assets/images/gradient-descent/gradient_descent_step_4.png").fragment
                img(src="assets/images/gradient-descent/gradient_descent_step_5.png").fragment
    section
        slide-with-header(header="Linear Regression - Optimierung - Gradient Descent")
            p Wie finden wir die #[span.highlight Richtung] herunter?
            p.fragment.highlight Richtung entspricht der Steigung der Kostenfunktion!
            p.fragment Wie finden wir die #[span.highlight Steigung] einer Funktion?
            p.fragment Analysis => Die #[span.highlight Ableitung] der Kostenfunktion gibt uns die Steigung/Richtung.
            div([mathjax]="metricCostFunctionDerivative").fragment
    section
        slide-with-header(header="Optimierung - Gradient Descent")
            tables-of-content-concepts-link([active]="conceptLabels.OPTIMIZATION_ALGORITHMS")
            div #[span.highlight Gradient Descent]-Algorithmus funktioniert wie folgt:
            ol
                li.fragment
                    div.d-flex.align-end(style={alignItems: "stretch"})
                        div.align-self-end #[span.highlight Initialisiere]&nbsp;
                        div.align-self-end([mathjax]="gradientDescentInit")
                        div.align-self-end mit zufälligen Werten.
                li.fragment
                    div.d-flex.align-end(style={alignItems: "stretch"})
                        div.align-self-end #[span.highlight Aktualisiere]:&nbsp;
                        div.align-self-end([mathjax]="gradientDescentUpdate")
                li.fragment.mt-2
                    div #[span.highlight Wiederhole] 2. bis eine Abbruchbedingung erreicht.
            p.mt-5.fragment.text-center.alert.alert-primary Auch bei #[span.highlight Non Convex Kostenfunktion] möglich
            p.mt-5.fragment.text-center.alert.alert-warning In der Praxis wird die #[span.highlight Analytische Methode für Lineare Regression] eingesetzt (schneller)
            // div.fragment
            //     div.mt-5.d-flex.justify-center.align-end(style={alignItems: "stretch"})
            //         div.align-self-end Wiederhole Schritt 2. bis&nbsp;
            //         div([mathjax]="gradientDescentStop")
    section
        slide-with-header(header="Linear Regression - Limits", [extra]="true")
            div.row
                div.col-5.offset-1
                    h6 Possible
                div.col-5
                    h6 Impossible (in Feature Space)
                div.col-1
            div.row.fragment
                div.col-1.m-auto
                    h6(style={transform: "rotate(-90deg)", whiteSpace: 'nowrap'}) 1 Feature
                div.col-5.p-2
                    img(src="assets/images/data-with-linear-regression-model-1d.png").limit-possible
                div.col-5.p-2
                    img(src="assets/images/polynomial-regression.png").limit-impossible
                div.col-1
            div.row.fragment
                div.col-1.m-auto
                    h6(style={transform: "rotate(-90deg)", whiteSpace: 'nowrap'}) 2 Features
                div.col-5.p-2
                    img(src="assets/images/data-with-linear-regression-model-2d.png").limit-possible
                div.col-5.p-2
                    img(src="assets/images/polynomial-regression-2d.png").limit-impossible
                div.col-1
    tables-of-content-machine-learning-algorithm
        div.row
            div.col-12
                div.d-flex.justify-start.flex-column.scale-05
                    div([mathjax]="linearRegressionFinal")
        div.row
            div.col-6
                div.d-flex.justify-start.flex-column.scale-05
                    div([mathjax]="metricMeanSquaredError")
            div.col-6
                img(src="assets/images/gradient-descent/gradient_descent_step_5.png").img-fluid